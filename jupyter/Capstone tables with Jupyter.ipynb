{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to This Jupyter example\n",
    "You simply type stuff in the \"In\" boxes, and it the play button.  You can also it shift-enter to play the box.  The cell menu lets you click multiple boxes.   This sort of thing can be the future of our self-paced spark spark training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val x = sc.cassandraTable(\"retail\",\"products_by_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.io.IOException\n",
       "Message: Failed to open native connection to Cassandra at {127.0.0.1}:9042\n",
       "StackTrace: com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:164)\n",
       "com.datastax.spark.connector.cql.CassandraConnector$$anonfun$2.apply(CassandraConnector.scala:150)\n",
       "com.datastax.spark.connector.cql.CassandraConnector$$anonfun$2.apply(CassandraConnector.scala:150)\n",
       "com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:31)\n",
       "com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:56)\n",
       "com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:81)\n",
       "com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:109)\n",
       "com.datastax.spark.connector.cql.CassandraConnector.withClusterDo(CassandraConnector.scala:120)\n",
       "com.datastax.spark.connector.cql.Schema$.fromCassandra(Schema.scala:241)\n",
       "com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.tableDef(CassandraTableRowReaderProvider.scala:51)\n",
       "com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef$lzycompute(CassandraTableScanRDD.scala:59)\n",
       "com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef(CassandraTableScanRDD.scala:59)\n",
       "com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.verify(CassandraTableRowReaderProvider.scala:150)\n",
       "com.datastax.spark.connector.rdd.CassandraTableScanRDD.verify(CassandraTableScanRDD.scala:59)\n",
       "com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:143)\n",
       "org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)\n",
       "org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)\n",
       "scala.Option.getOrElse(Option.scala:120)\n",
       "org.apache.spark.rdd.RDD.partitions(RDD.scala:217)\n",
       "org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1255)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)\n",
       "org.apache.spark.rdd.RDD.withScope(RDD.scala:286)\n",
       "org.apache.spark.rdd.RDD.take(RDD.scala:1250)\n",
       "com.datastax.spark.connector.rdd.CassandraRDD.take(CassandraRDD.scala:121)\n",
       "com.datastax.spark.connector.rdd.CassandraRDD.take(CassandraRDD.scala:122)\n",
       "$line64.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:20)\n",
       "$line64.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:25)\n",
       "$line64.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n",
       "$line64.$read$$iwC$$iwC$$iwC.<init>(<console>:29)\n",
       "$line64.$read$$iwC$$iwC.<init>(<console>:31)\n",
       "$line64.$read$$iwC.<init>(<console>:33)\n",
       "$line64.$read.<init>(<console>:35)\n",
       "$line64.$read$.<init>(<console>:39)\n",
       "$line64.$read$.<clinit>(<console>)\n",
       "$line64.$eval$.<init>(<console>:7)\n",
       "$line64.$eval$.<clinit>(<console>)\n",
       "$line64.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:498)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:301)\n",
       "com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:296)\n",
       "com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)\n",
       "com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:295)\n",
       "com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:295)\n",
       "com.ibm.spark.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:123)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Case Class Example with some markdown\n",
    "Lets look at the stores table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case class Store(\n",
    "                  store_id: Int,\n",
    "                  address: String,\n",
    "                  address_2: String,\n",
    "                  address_3: String,\n",
    "                  city: String,\n",
    "                  state: String,\n",
    "                  zip: Long,\n",
    "                  size_in_sf: Int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD based on the store table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val stores = sc.cassandraTable(\"retail\",\"stores\").select(\"store_id\",\"address\",\n",
    "      \"address_2\",\"address_3\",\"city\",\"state\",\"zip\",\"size_in_sf\"\n",
    "    ).as(Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stores.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another RDD based on receipts.  \n",
    "### No case class as it's only two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val receipts = sc.cassandraTable(\"retail\",\"receipts_by_store_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scala.math.BigDecimal.RoundingMode\n",
    "\n",
    "val total_receipts_by_store = receipts.map(r => (r.getInt(\"store_id\"), r.getDecimal(\"receipt_total\").setScale(2,RoundingMode.HALF_EVEN) )  ).reduceByKey(_+_)   // Add up by store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_receipts_by_store take 10 foreach println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CQL",
   "language": "CQL",
   "name": "cql"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
